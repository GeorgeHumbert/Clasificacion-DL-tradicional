{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a89b41ed-93ee-4fbc-a95c-f121341e4183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['col_0', 'col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7',\n",
      "       'col_8', 'col_9',\n",
      "       ...\n",
      "       'col_191', 'col_192', 'col_193', 'col_194', 'col_195', 'col_196',\n",
      "       'col_197', 'col_198', 'col_199', 'sentiment'],\n",
      "      dtype='object', length=201)\n",
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1047704\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1047704/fs/1039431/fg/1207640\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e9b0a979ab4151ab178d3f624a76f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/40000 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: imdb_reviews_dl_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/1047704/jobs/named/imdb_reviews_dl_1_offline_fg_materialization/executions\n",
      "Datos guardados en el Feature Store de Hopsworks.\n"
     ]
    }
   ],
   "source": [
    "# Paso 1: Importar las bibliotecas necesarias\n",
    "import hopsworks\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Paso 2: Cargar el dataset\n",
    "data_path = \"data/IMDB Dataset.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Mostrar las primeras filas del dataset\n",
    "df.head()\n",
    "\n",
    "# Paso 3: Preprocesar el texto\n",
    "# Convertir a minúsculas\n",
    "df['review'] = df['review'].str.lower()\n",
    "\n",
    "# Eliminar caracteres especiales\n",
    "df['review'] = df['review'].str.replace(r'<.*?>', '', regex=True)  # Eliminar etiquetas HTML\n",
    "\n",
    "# Tokenización y secuencias\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df['review'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(df['review'])\n",
    "padded = pad_sequences(sequences, maxlen=200)\n",
    "\n",
    "# Paso 4: Codificación de etiquetas\n",
    "df['sentiment'] = df['sentiment'].replace({'positive': 1, 'negative': 0})\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded, df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear un DataFrame con las secuencias y la etiqueta\n",
    "df_feature_store = pd.DataFrame(X_train)\n",
    "\n",
    "# Renombrar las columnas numéricas a 'col_0', 'col_1', ..., 'col_n'\n",
    "df_feature_store.columns = ['col_' + str(i) for i in df_feature_store.columns]\n",
    "\n",
    "# Añadir la columna de etiquetas\n",
    "df_feature_store['sentiment'] = y_train.values\n",
    "\n",
    "# Verificar que los nombres de las columnas sean válidos\n",
    "print(df_feature_store.columns)\n",
    "\n",
    "# Paso 5: Conectar a Hopsworks y guardar los datos en el Feature Store\n",
    "load_dotenv()  # Cargar la API Key desde el archivo .env\n",
    "api_key = os.getenv(\"HOPSWORKS_API_KEY\")\n",
    "\n",
    "# Conectarse a Hopsworks\n",
    "project = hopsworks.login(api_key_value=api_key)\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "# Crear una columna de índice única para usar como clave primaria\n",
    "df_feature_store['id'] = range(len(df_feature_store))  # Crear columna de ID único\n",
    "\n",
    "# Crear el Feature Group con la columna 'id' como primary_key\n",
    "imdb_fg = fs.get_or_create_feature_group(\n",
    "    name=\"imdb_reviews_dl\",\n",
    "    version=1,\n",
    "    description=\"Preprocessed IMDB reviews for deep learning classification\",\n",
    "    primary_key=[\"id\"],  # Definir la columna 'id' como clave primaria\n",
    "    online_enabled=True\n",
    ")\n",
    "\n",
    "# Guardar el DataFrame en el Feature Store\n",
    "imdb_fg.insert(df_feature_store)\n",
    "\n",
    "print(\"Datos guardados en el Feature Store de Hopsworks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9809f6f3-2e79-4f43-969a-0b0695a5ddc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
